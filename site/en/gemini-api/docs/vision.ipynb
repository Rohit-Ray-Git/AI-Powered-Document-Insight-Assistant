{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohit-Ray-Git/AI-Powered-Document-Insight-Assistant/blob/main/site/en/gemini-api/docs/vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "084u8u0DpBlo"
      },
      "source": [
        "# Explore vision capabilities with the Gemini API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFWzQEqNosrS"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs/vision\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/vision.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/vision.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c5e92a74e64"
      },
      "source": [
        "The Gemini API is able to process images and videos, enabling a multitude of\n",
        " exciting developer use cases. Some of Gemini's vision capabilities include\n",
        " the ability to:\n",
        "\n",
        "*   Caption and answer questions about images\n",
        "*   Transcribe and reason over PDFs, including long documents up to 2 million token context window\n",
        "*   Describe, segment, and extract information from videos,\n",
        "including both visual frames and audio, up to 90 minutes long\n",
        "*   Detect objects in an image and return bounding box coordinates for them\n",
        "\n",
        "This tutorial demonstrates some possible ways to prompt the Gemini API with\n",
        "images and video input, provides code examples,\n",
        "and outlines prompting best practices with multimodal vision capabilities.\n",
        "All output is text-only."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxCstRHvpX0r"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Before you use the File API, you need to install the Gemini API SDK package and configure an API key. This section describes how to complete these setup steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6J_rV2ipmj_"
      },
      "source": [
        "### Install the Python SDK and import packages\n",
        "\n",
        "The Python SDK for the Gemini API is contained in the [google-generativeai](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mN8x8DPgu9Kv"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NInUZ4hwDq6d"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0x3xmmWrDtEH"
      },
      "outputs": [],
      "source": [
        "import google.generativeai as genai\n",
        "from IPython.display import Markdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8g4hTRotheH"
      },
      "source": [
        "### Set up your API key\n",
        "\n",
        "The File API uses API keys for authentication and access. Uploaded files are associated with the project linked to the API key. Unlike other Gemini APIs that use API keys, your API key also grants access to data you've uploaded to the File API, so take extra care in keeping your API key secure. For more on keeping your keys\n",
        "secure, see [Best practices for using API\n",
        "keys](https://support.google.com/googleapi/answer/6310037).\n",
        "\n",
        "Store your API key in a Colab Secret named `GOOGLE_API_KEY`. If you don't already have an API key, or are unfamiliar with Colab Secrets, refer to the [Authentication quickstart](https://github.com/google-gemini/gemini-api-cookbook/blob/main/quickstarts/Authentication.ipynb)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d6lYXRcjthKV"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-z4zsCUlaru"
      },
      "source": [
        "## Prompting with images\n",
        "\n",
        "In this tutorial, you will upload images using the File API or as inline data and generate content based on those images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKNehP2tr3Cr"
      },
      "source": [
        "### Technical details (images)\n",
        "Gemini 1.5 Pro and Flash support a maximum of 3,600 image files.\n",
        "\n",
        "Images must be in one of the following image data [MIME types](https://developers.google.com/drive/api/guides/ref-export-formats):\n",
        "\n",
        "-   PNG - `image/png`\n",
        "-   JPEG - `image/jpeg`\n",
        "-   WEBP - `image/webp`\n",
        "-   HEIC - `image/heic`\n",
        "-   HEIF - `image/heif`\n",
        "\n",
        "Each image is equivalent to 258 tokens.\n",
        "\n",
        "While there are no specific limits to the number of pixels in an image besides the modelâ€™s context window, larger images are scaled down to a maximum resolution of 3072x3072 while preserving their original aspect ratio, while smaller images are scaled up to 768x768 pixels. There is no cost reduction for images at lower sizes, other than bandwidth, or performance improvement for images at higher resolution.\n",
        "\n",
        "For best results:\n",
        "\n",
        "*   Rotate images to the correct orientation before uploading.\n",
        "*   Avoid blurry images.\n",
        "*   If using a single image, place the text prompt after the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fa34d5c0db8"
      },
      "source": [
        "## Image input\n",
        "\n",
        "For total image payload size less than 20MB, it's recommended to either upload\n",
        "base64 encoded images or directly upload locally stored image files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8336e412da3e"
      },
      "source": [
        "### Base64 encoded images\n",
        "\n",
        "You can upload public image URLs by encoding them as Base64 payloads.\n",
        "You can use the httpx library to fetch the image URLs.\n",
        "The following code example shows how to do this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aa9a0e452544",
        "outputId": "3c4547ed-a0a1-42d9-d180-9f98ceada65e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">A view of London, England, showcasing the city's iconic landmarks under a cloudy sky.  Prominently featured are the London Eye, Big Ben (Elizabeth Tower), the Houses of Parliament, and a glimpse of the Shard in the background.  The image captures the mix of historical and modern architecture, along with the River Thames and the bustling cityscape. The viewpoint is elevated, providing a broad perspective over the rooftops and streets below."
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import httpx\n",
        "import base64\n",
        "\n",
        "# Retrieve an image\n",
        "image_path = \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg/2560px-Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg\"\n",
        "image = httpx.get(image_path)\n",
        "\n",
        "# Choose a Gemini model\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "\n",
        "# Create a prompt\n",
        "prompt = \"Caption this image.\"\n",
        "response = model.generate_content(\n",
        "    [\n",
        "        {\n",
        "            \"mime_type\": \"image/jpeg\",\n",
        "            \"data\": base64.b64encode(image.content).decode(\"utf-8\"),\n",
        "        },\n",
        "        prompt,\n",
        "    ]\n",
        ")\n",
        "\n",
        "Markdown(\">\" + response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f47333dabe62"
      },
      "source": [
        "### Multiple images\n",
        "\n",
        "To prompt with multiple images in Base64 encoded format, you can do the\n",
        "following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2816ea3d2d91",
        "outputId": "f746cb24-59c9-48ed-8b9e-483332c8799c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Image 1 (London Skyline):**\n\n* Houses of Parliament (including Big Ben/Elizabeth Tower)\n* London Eye\n* The Shard\n* River Thames\n* Various other buildings and skyscrapers of London\n* Trees\n* Streets\n* Construction cranes\n\n**Image 2 (Jetpack Backpack Sketch):**\n\n* Backpack shape\n* Padded strap support\n* USB-C charging port\n* Retractible boosters with steam exhaust\n* Text labels indicating features:\n    * \"JETPACK BACKPACK\"\n    * \"FITS 18\" LAPTOP\"\n    * \"LIGHTWEIGHT\"\n    * \"LOOKS LIKE A NORMAL BACKPACK\"\n    * \"RETRACTABLE BOOSTERS\"\n    * \"STEAM-POWERED, GREEN/CLEAN\"\n    * \"PADDED STRAP SUPPORT\"\n    * \"USB-C CHARGING\"\n    * \"15-MIN BATTERY LIFE\""
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import httpx\n",
        "import base64\n",
        "\n",
        "# Retrieve two images\n",
        "image_path_1 = \"https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg/2560px-Palace_of_Westminster_from_the_dome_on_Methodist_Central_Hall.jpg\"\n",
        "image_path_2 = \"https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg\"\n",
        "\n",
        "image_1 = httpx.get(image_path_1)\n",
        "image_2 = httpx.get(image_path_2)\n",
        "\n",
        "# Create a prompt\n",
        "prompt = \"Generate a list of all the objects contained in both images.\"\n",
        "\n",
        "response = model.generate_content([\n",
        "{'mime_type':'image/jpeg', 'data': base64.b64encode(image_1.content).decode('utf-8')},\n",
        "{'mime_type':'image/jpeg', 'data': base64.b64encode(image_2.content).decode('utf-8')}, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lm862F3zthiI"
      },
      "source": [
        "### Upload one or more locally stored image files\n",
        "\n",
        "Alternatively, you can upload one or more locally stored image files..\n",
        "\n",
        "You can download and use our drawings of [piranha-infested waters](https://storage.googleapis.com/generativeai-downloads/images/piranha.jpg) and a [firefighter with a cat](https://storage.googleapis.com/generativeai-downloads/images/firefighter.jpg). First, save these files to your local directory.\n",
        "\n",
        "Then click **Files** on the left sidebar. For each file, click the **Upload** button, then navigate to that file's location and upload it:\n",
        "\n",
        "<img width=400 src=\"https://ai.google.dev/tutorials/images/colab_upload.png\">\n",
        "\n",
        "When the combination of files and system instructions that you intend to send is larger than 20 MB in size, use the File API to upload those files. Smaller files can instead be called locally from the Gemini API:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XzMhQ8MWub5_"
      },
      "outputs": [],
      "source": [
        "import PIL.Image\n",
        "\n",
        "sample_file_2 = PIL.Image.open('img1.jpg')\n",
        "sample_file_3 = PIL.Image.open('img2.jpeg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "da11223550a9",
        "outputId": "99d8ba01-b2c8-4b56-9ee3-2e0096fbe37e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "(Upbeat, samba-style music plays)\n\n**Singer:** Feeling the heat? Like a piranha's bite?\nHouse on fire, burning bright?\nDon't delay, don't you fret!\nCall the firemen, haven't you met?\n\n**(Tempo changes to a more heroic march)**\n\n**Singer:**  Brave and strong, fast and bold,\nPutting out fires, young and old!\nFrom flames so high, to embers low,\nThey'll stop the blaze, put on a show!\n\n**(Music returns to samba)**\n\n**Singer:** So when your house is feeling hot,\nLike a piranha in a pot,\nDon't get burned, don't despair,\nCall the fire department, they'll be there!\n\n**(Announcer, clear and confident):**  For all your fire emergencies, call 9-1-1.  Your safety is our priority!\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Create a prompt.\n",
        "prompt = \"Write an advertising jingle based on the items in both images.\"\n",
        "\n",
        "response = model.generate_content([sample_file_2, sample_file_3, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "736c83de95a1"
      },
      "source": [
        "Note that these inline data calls don't include many of the features available\n",
        "through the File API, such as getting file metadata,\n",
        "[listing](https://ai.google.dev/gemini-api/docs/vision?lang=python#list-files),\n",
        "or [deleting files](https://ai.google.dev/gemini-api/docs/vision?lang=python#delete-files)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d6f7af7c2ff"
      },
      "source": [
        "### Large image payloads"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsdNkDszLBmQ"
      },
      "source": [
        "#### Upload an image file using the File API\n",
        "\n",
        "When the combination of files and system instructions that you intend to send is larger than 20 MB in size, use the File API to upload those files.\n",
        "\n",
        "**NOTE**: The File API lets you store up to 20 GB of files per project, with a per-file maximum size of 2 GB. Files are stored for 48 hours. They can be accessed in that period with your API key, but cannot be downloaded from the API. It is available at no cost in all regions where the Gemini API is available."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfa2VSqEsulq"
      },
      "source": [
        "Upload the image using [`media.upload`](https://ai.google.dev/api/rest/v1beta/media/upload) and print the URI, which is used as a reference in Gemini API calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2e9f9469b337",
        "outputId": "75b5bf0b-58fc-49f3-d87d-8d84be7ecd80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  349k  100  349k    0     0  2638k      0 --:--:-- --:--:-- --:--:-- 2645k\n"
          ]
        }
      ],
      "source": [
        "!curl -o jetpack.jpg https://storage.googleapis.com/generativeai-downloads/images/jetpack.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "N9NxXGZKKusG",
        "outputId": "7f4a83dc-2303-46e8-a0ab-44c4a68308c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file 'Jetpack drawing' as: https://generativelanguage.googleapis.com/v1beta/files/yps21jkbw1i7\n"
          ]
        }
      ],
      "source": [
        "# Upload the file and print a confirmation.\n",
        "sample_file = genai.upload_file(path=\"jetpack.jpg\",\n",
        "                            display_name=\"Jetpack drawing\")\n",
        "\n",
        "print(f\"Uploaded file '{sample_file.display_name}' as: {sample_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cto22vhKOvGQ"
      },
      "source": [
        "The `response` shows that the File API stored the specified `display_name` for the uploaded file and a `uri` to reference the file in Gemini API calls. Use `response` to track how uploaded files are mapped to URIs.\n",
        "\n",
        "Depending on your use case, you can also store the URIs in structures such as a `dict` or a database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds5iJlaembWe"
      },
      "source": [
        "#### Verify image file upload and get metadata\n",
        "\n",
        "You can verify the API successfully stored the uploaded file and get its metadata by calling [`files.get`](https://ai.google.dev/api/rest/v1beta/files/get) through the SDK. Only the `name` (and by extension, the `uri`) are unique. Use `display_name` to identify files only if you manage uniqueness yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kLFsVLFHOWSV",
        "outputId": "c9c3c986-b648-4212-9f64-23c96d38440c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved file 'Jetpack drawing' as: https://generativelanguage.googleapis.com/v1beta/files/yps21jkbw1i7\n"
          ]
        }
      ],
      "source": [
        "file = genai.get_file(name=sample_file.name)\n",
        "print(f\"Retrieved file '{file.display_name}' as: {sample_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqzIGKBmnFoJ"
      },
      "source": [
        "Depending on your use case, you can store the URIs in structures, such as a `dict` or a database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPPOECHzsIGJ"
      },
      "source": [
        "#### Prompt with the uploaded image and text\n",
        "\n",
        "After uploading the file, you can make GenerateContent requests that reference the File API URI. Select the generative model and provide it with a text prompt and the uploaded image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZYVFqmLkl5nE",
        "outputId": "38a90416-8089-4a09-faf9-58dc3e2881e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Manufacturing a jetpack backpack, even a conceptual steam-powered one, would require a multi-stage process involving several specialized areas:\n\n1. **Backpack Construction:** This would follow standard backpack manufacturing techniques.\n    * **Fabric Cutting and Sewing:**  Durable, lightweight, and possibly fire-resistant fabrics (nylon, Cordura, etc.) would be cut and sewn to form the main compartment, straps (with added padding and reinforcement for the jetpack thrust), and other compartments.\n    * **Hardware:**  Buckles, zippers, and other hardware would be attached.\n\n2. **Jetpack System Fabrication:** This is where specialized manufacturing comes in.\n    * **Booster Construction:**  Small, retractable steam-powered boosters would need to be engineered. This might involve miniature boilers, valves, and nozzles, likely using lightweight, heat-resistant metals like titanium or specialized alloys. Precision machining and welding would be essential.\n    * **Steam Generation:** A compact, lightweight steam generator would be needed. This could involve a miniaturized boiler heated by a powerful, compact energy source (perhaps a high-density battery, though not explicitly mentioned in the drawing). This requires expertise in thermodynamics, materials science, and miniaturization.\n    * **Control System:**  A system of valves and controls (possibly electronic) would regulate steam flow to the boosters for controlled thrust. This involves electronics manufacturing and software development for the control system.\n\n3. **Power Source Production:**  If using batteries, a specialized battery manufacturing process would be required for high energy density and rapid discharge capabilities.\n\n4. **Assembly and Testing:**\n    * **Integration:**  The backpack and jetpack components would be carefully integrated and secured. This would involve fitting the steam generator, boosters, and control system within the backpack structure while maintaining balance and user comfort.\n    * **Quality Control:**  Rigorous testing would be essential. This would include pressure tests for the steam system, thrust tests for the boosters, flight stability tests, and safety checks for the entire system.  Given the nature of a jetpack, certification and regulatory compliance would be critical before market release.\n\n5. **USB-C Charging System Integration:**  Standard USB-C charging ports and circuitry would be integrated for charging the power source (presumably the battery that powers the steam generator).\n\nThis is a simplified overview. A real-world jetpack backpack would require much more complex engineering and manufacturing processes. The steam-powered aspect adds further complexity, as steam power is not typically used for personal flight devices due to efficiency and safety concerns.\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Prompt the model with text and the previously uploaded image.\n",
        "response = model.generate_content([sample_file, \"Describe how this product might be manufactured.\"])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c63c1a7a8e32"
      },
      "source": [
        "## Capabilties\n",
        "\n",
        "This section outlines specific vision capabilities of the Gemini model, including object detection and bounding box coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e16d742407a"
      },
      "source": [
        "### Get bounding boxes\n",
        "\n",
        "Gemini models are trained to return bounding box coordinates as relative widths or heights in the range of [0, 1]. These values are then scaled by 1000 and converted to integers. Effectively, the coordinates represent the bounding box on a 1000x1000 pixel version of the image. Therefore, you'll need to convert these coordinates back to the dimensions of your original image to accurately map the bounding boxes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "778dd36334f4",
        "outputId": "60f1123d-71ff-4066-ddbd-1cc423eba9dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "I detect the following object and its bounding box.\n- 275 159 729 841 fish\n"
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Create a prompt to detect bounding boxes.\n",
        "prompt = \"Return a bounding box for each of the objects in this image in [ymin, xmin, ymax, xmax] format.\"\n",
        "response = model.generate_content([sample_file_2, prompt])\n",
        "\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8e422c55df2"
      },
      "source": [
        "The model returns bounding box coordinates in the format\n",
        "`[ymin, xmin, ymax, xmax]`. To convert these normalized coordinates\n",
        "to the pixel coordinates of your original image, follow these steps:\n",
        "\n",
        "1.    Divide each output coordinate by 1000.\n",
        "1.    Multiply the x-coordinates by the original image width.\n",
        "1.    Multiply the y-coordinates by the original image height.\n",
        "\n",
        "To explore more detailed examples of generating bounding box coordinates and\n",
        "visualizing them on images, review our [Object Detection cookbook example](https://github.com/google-gemini/cookbook/blob/main/examples/Object_detection.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaUZc1mvLkHY"
      },
      "source": [
        "## Prompting with video\n",
        "\n",
        "In this tutorial, you will upload a video using the File API and generate content based on those images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDN32NDPxXGX"
      },
      "source": [
        "### Technical details (video)\n",
        "\n",
        "Gemini 1.5 Pro and Flash support up to approximately an hour of video data.\n",
        "\n",
        "Video must be in one of the following video format [MIME types](https://developers.google.com/drive/api/guides/ref-export-formats):\n",
        "  -   `video/mp4`\n",
        "  -   `video/mpeg`\n",
        "  -   `video/mov`\n",
        "  -   `video/avi`\n",
        "  -   `video/x-flv`\n",
        "  -   `video/mpg`\n",
        "  -   `video/webm`\n",
        "  -   `video/wmv`\n",
        "  -   `video/3gpp`\n",
        "\n",
        "The File API service currently extracts image frames from videos at 1 frame per second (FPS) and audio at 1Kbps, single channel, adding timestamps every second. These rates are subject to change in the future for improvements in inference.\n",
        "\n",
        "**NOTE:** The finer details of fast action sequences may be lost at the 1 FPS frame sampling rate. Consider slowing down high-speed clips for improved inference quality.\n",
        "\n",
        "Individual frames are 258 tokens, and audio is 32 tokens per second. With metadata, each second of video becomes ~300 tokens, which means a 1M context window can fit slightly less than an hour of video.\n",
        "\n",
        "To ask questions about time-stamped locations, use the format `MM:SS`, where the first two digits represent minutes and the last two digits represent seconds.\n",
        "\n",
        "For best results:\n",
        "\n",
        "*   Use one video per prompt.\n",
        "*   If using a single video, place the text prompt after the video."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNvhBdoDFnTC"
      },
      "source": [
        "### Upload a video file to the File API\n",
        "\n",
        "**NOTE**: The File API lets you store up to 20 GB of files per project, with a per-file maximum size of 2 GB. Files are stored for 48 hours. They can be accessed in that period with your API key, but they cannot be downloaded using any API. It is available at no cost in all regions where the Gemini API is available.\n",
        "\n",
        "The File API accepts video file formats directly. This example uses the short NASA film [\"Jupiter's Great Red Spot Shrinks and Grows\"](https://www.youtube.com/watch?v=JDi4IdtvDVE0). Credit: Goddard Space Flight Center (GSFC)/David Ladd (2018).\n",
        "\n",
        "> \"Jupiter's Great Red Spot Shrinks and Grows\" is in the public domain and does not show identifiable people. ([NASA image and media usage guidelines.](https://www.nasa.gov/nasa-brand-center/images-and-media/))\n",
        "\n",
        "Start by retrieving the short video:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "V4XeFdX1rxaE",
        "outputId": "0131a967-adb0-41a2-945d-1d2cb1173264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-26 09:34:34--  https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.194.207, 142.250.152.207, 172.217.214.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.194.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238090979 (227M) [video/mp4]\n",
            "Saving to: â€˜GreatRedSpot.mp4â€™\n",
            "\n",
            "GreatRedSpot.mp4    100%[===================>] 227.06M   187MB/s    in 1.2s    \n",
            "\n",
            "2024-12-26 09:34:36 (187 MB/s) - â€˜GreatRedSpot.mp4â€™ saved [238090979/238090979]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/generativeai-downloads/images/GreatRedSpot.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZusSiIg2T6ls"
      },
      "source": [
        "Upload the video to the File API and print the URI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_HzrDdp2Q1Cu",
        "outputId": "2bdf417d-ec8b-4d5d-d038-e2aa142c319c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file...\n",
            "Completed upload: https://generativelanguage.googleapis.com/v1beta/files/80xqsj1d7lfg\n"
          ]
        }
      ],
      "source": [
        "video_file_name = \"GreatRedSpot.mp4\"\n",
        "\n",
        "print(f\"Uploading file...\")\n",
        "video_file = genai.upload_file(path=video_file_name)\n",
        "print(f\"Completed upload: {video_file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOZmTUb4FWOa"
      },
      "source": [
        "### Verify file upload and check state\n",
        "\n",
        "Verify the API has successfully received the files by calling the [`files.get`](https://ai.google.dev/api/rest/v1beta/files/get) method.\n",
        "\n",
        "**NOTE**: Video files have a `State` field in the File API. When a video is uploaded, it will be in the `PROCESSING` state until it is ready for inference. Only `ACTIVE` files can be used for model inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "SHMVCWHkFhJW",
        "outputId": "56cca500-f59b-4b5d-e739-bba6bc7741fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "."
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Check whether the file is ready to be used.\n",
        "while video_file.state.name == \"PROCESSING\":\n",
        "    print('.', end='')\n",
        "    time.sleep(10)\n",
        "    video_file = genai.get_file(video_file.name)\n",
        "\n",
        "if video_file.state.name == \"FAILED\":\n",
        "  raise ValueError(video_file.state.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIIHsvQt0_W"
      },
      "source": [
        "### Prompt with a video and text\n",
        "\n",
        "Once the uploaded video is in the `ACTIVE` state, you can make `GenerateContent` requests that specify the File API URI for that video. Select the generative model and provide it with the uploaded video and a text prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sHH0ZR6Yt42S",
        "outputId": "0cf41246-3576-4b47-b26c-d0a7886b6433",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Here is a summary of the video and a quiz about Jupiterâ€™s Great Red Spot:\n\nJupiter is the largest and oldest planet in our solar system, dating back 4.5 billion years. Itâ€™s made of the same elements as stars but never became massive enough to ignite. Itâ€™s comprised mostly of swirled gases and liquids and its iconic feature, the Great Red Spot, is a giant, centuries-old storm.  \n\nScientists have noticed that the Great Red Spot is evolving. The spotâ€™s color is deepening, and it is shrinking and becoming more circular. These scientists theorized that as the storm shrinks, the wind speeds should increase, like a spinning ice skater who pulls in her arms.Â \n\nHowever, recent data shows that the spot isnâ€™t rotating faster, itâ€™s getting taller. The change is analogous to the way clay spins as it is molded on a potterâ€™s wheel. Although itâ€™s shrinking horizontally, the spot is increasing vertically.Â Â \n\nThe Great Red Spot used to be large enough to hold three Earths, but itâ€™s now just a little bigger than one. The data is based on analyses from NASA missions like Voyager, Hubble, and Juno. Scientists are hopeful that further investigation will reveal more secrets of the mysterious Great Red Spot.\n\n\nQuiz:\n\n1. Which planet is considered the oldest and largest in our solar system?\nA. Mars\nB. Earth\nC. Jupiter\nD. Saturn\n\n2. What is the Great Red Spot?\nA. A gigantic volcano\nB. A giant storm\nC. A giant crater\nD. An impact zone\n\n3. What two characteristics of the Great Red Spot are changing over time?\nA. Size and shape\nB. Temperature and depth\nC. Composition and color\nD. Rotation speed and visibility\n\n4. How does the shrinking of the Great Red Spot affect its wind speed?\nA. Wind speeds increase\nB. Wind speeds decrease\nC. Wind speeds remain constant\nD. Wind speeds fluctuate randomly\n\n5. What analogy is used to explain the change in height of the Great Red Spot?\nA. A spinning top\nB. A figure skater pulling in her arms\nC. Molding clay on a potter's wheel\nD. An inflatable balloon being deflated\n\nAnswer Key:\n1. C\n2. B\n3. A\n4. C\n5. C"
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Create the prompt.\n",
        "prompt = \"Summarize this video. Then create a quiz with answer key based on the information in the video.\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([video_file, prompt],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "\n",
        "# Print the response, rendering any Markdown\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS5NmQeXLqeS"
      },
      "source": [
        "### Refer to timestamps in the content\n",
        "\n",
        "You can use timestamps of the form `MM:SS` to refer to specific moments in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ypZuGQ-2LqeS",
        "outputId": "08197e1c-2347-40fe-ce18-84319a6ad5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Sure! At [00:00:05], the narrator explains that scientists expect that if Jupiterâ€™s Great Red Spot shrinks, its wind speed should increase. They compare this expected outcome to the way an ice skater spins faster when she pulls in her arms. Then at [00:00:19], the video displays data from 2014 to 2017 charting relative height and latitude. While the spot is shrinking, it is also growing taller. The analogy of someone working with clay on a potterâ€™s wheel is used to explain this phenomenon. As the large lump of clay spins on the potterâ€™s wheel, forces are pushing it upward, making it taller. Similarly, while the Great Red Spot appears to shrink from our perspective, it is also growing taller."
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Create the prompt.\n",
        "prompt = \"What are the examples given at 01:05 and 01:19 supposed to show us?\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([prompt, video_file],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "Markdown(response.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQE0XjgMZSJo"
      },
      "source": [
        "### Transcribe video and provide visual descriptions\n",
        "\n",
        "The Gemini models can transcribe and provide visual descriptions of video content\n",
        "by processing both the audio track and visual frames.\n",
        "For visual descriptions, the model samples the video at a rate of **1 frame\n",
        "per second**. This sampling rate may affect the level of detail in the\n",
        "descriptions, particularly for videos with rapidly changing visuals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_JrcMsYnYXpJ",
        "outputId": "4ca6318a-b96d-4fbb-8eec-5024470ffbf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making LLM inference request...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 1477.71ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TooManyRequests",
          "evalue": "429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-c338683651c5>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Make the LLM request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Making LLM inference request...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m response = model.generate_content([video_file, prompt],\n\u001b[0m\u001b[1;32m     10\u001b[0m                                   request_options={\"timeout\": 600})\n\u001b[1;32m     11\u001b[0m \u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mesponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    831\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTooManyRequests\u001b[0m: 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: Resource has been exhausted (e.g. check quota)."
          ]
        }
      ],
      "source": [
        "# Create the prompt.\n",
        "prompt = \"Transcribe the audio from this video, giving timestamps for salient events in the video. Also provide visual descriptions.\"\n",
        "\n",
        "# Choose a Gemini model.\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")\n",
        "\n",
        "# Make the LLM request.\n",
        "print(\"Making LLM inference request...\")\n",
        "response = model.generate_content([video_file, prompt],\n",
        "                                  request_options={\"timeout\": 600})\n",
        "Markdown(esponse.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VosrkvAyrx-v"
      },
      "source": [
        "## List files\n",
        "\n",
        "You can list all uploaded files and their URIs using `files.list_files()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O82e6E2Irzlj",
        "outputId": "0336b54a-2877-46d2-c279-c997a2c34e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GreatRedSpot.mp4, URI: https://generativelanguage.googleapis.com/v1beta/files/80xqsj1d7lfg\n",
            "Jetpack drawing, URI: https://generativelanguage.googleapis.com/v1beta/files/yps21jkbw1i7\n"
          ]
        }
      ],
      "source": [
        "# List all files\n",
        "for file in genai.list_files():\n",
        "    print(f\"{file.display_name}, URI: {file.uri}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diCy9BgjLqeS"
      },
      "source": [
        "## Delete files\n",
        "\n",
        "Files are automatically deleted after 2 days. You can also manually delete them using `files.delete()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYyi5PrKLqeb"
      },
      "outputs": [],
      "source": [
        "genai.delete_file(video_file.name)\n",
        "print(f'Deleted file {video_file.uri}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vision.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}